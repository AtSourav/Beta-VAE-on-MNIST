{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDK05KgxBmciraVw5y7LPH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtSourav/CatsnDogs_VAE/blob/main/CatsnDogs_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to build a VAE in keras with the encoder and decoder based on CNNs."
      ],
      "metadata": {
        "id": "4ur1bU8y1uHM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uoG7iO2skKtn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import losses\n",
        "from keras import layers\n",
        "from keras import utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = (160,160,3)\n",
        "latent_dim = 16"
      ],
      "metadata": {
        "id": "Rc8U_BGj2L9P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = keras.Input(shape=input_size)\n",
        "\n",
        "x = layers.Conv2D(16, 3, padding=\"valid\")(encoder_input)\n",
        "x = layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\")(x)    # with strides=None this defaults to pool_size\n",
        "x = layers.BatchNormalization(axis=-1)(x) # the default data_format in the conv2d is \"channels last\", we want to normalize across the channels, hence we set axis=-1\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(32, 3, padding=\"valid\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\")(x)\n",
        "x = layers.BatchNormalization(axis=-1)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(64, 3, padding=\"valid\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\")(x)\n",
        "x = layers.BatchNormalization(axis=-1)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(128, 3, padding=\"valid\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\")(x)\n",
        "x = layers.BatchNormalization(axis=-1)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Flatten()(x)       # dimension of vector produced 8*8*256\n",
        "\n",
        "# we won't add any extra dense layers for now\n",
        "\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "\n",
        "def sampling(arg):\n",
        "  z_m, z_log_v = arg\n",
        "  batch = tf.shape(z_m)[0]\n",
        "  dim = tf.shape(z_m)[1]\n",
        "  eps = tf.random.normal(shape=(batch,dim))\n",
        "  return z_m + tf.exp(0.5*z_log_v)*eps\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean,z_log_var])   # we feed the sampling function in to a Lambda layer to build form a layer for the architecture as keras needs\n",
        "\n",
        "encoder = keras.Model(encoder_input, [z_mean, z_log_var, z], name='encoder')           # the second argument specifies that the encoder outputs [z_mean, z_log_var, z] for each input.\n",
        "encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaWmRig39WZE",
        "outputId": "dd92c7eb-3c4d-4412-fea8-ea76009e1835"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 158, 158, 16  448         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 79, 79, 16)   0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 79, 79, 16)  64          ['max_pooling2d[0][0]']          \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 79, 79, 16)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 77, 77, 32)   4640        ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 38, 38, 32)  0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 38, 38, 32)  128         ['max_pooling2d_1[0][0]']        \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 38, 38, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 36, 36, 64)   18496       ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 18, 18, 64)  0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 18, 18, 64)  256         ['max_pooling2d_2[0][0]']        \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 18, 18, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 16, 16, 128)  73856       ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 128)   0           ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 8, 8, 128)   512         ['max_pooling2d_3[0][0]']        \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 8, 8, 128)    0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 8192)         0           ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 16)           131088      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 16)           131088      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 16)           0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 360,576\n",
            "Trainable params: 360,096\n",
            "Non-trainable params: 480\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of trainable parameters might just be too big for the dataset, possibility of overtraining, we'll see how it goes. Let's make the decoder now."
      ],
      "metadata": {
        "id": "d7reegoIckKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_input = keras.Input(shape=(latent_dim,))\n",
        "\n",
        "x = layers.Dense(10*10*128)(latent_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((10,10,128))(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(64, 3, strides=2, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "                                                        # axis=-1 is set by default\n",
        "x = layers.Conv2DTranspose(32, 3, strides=2, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(16, 3, strides=2, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "decoder_output = layers.Conv2DTranspose(3, 3, activation='sigmoid', strides=2, padding='same')(x)\n",
        "\n",
        "decoder = keras.Model(latent_input, decoder_output, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "60HAUzK8as95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b56550-fd64-4eab-9b3a-d6decddf5b79"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 16)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 12800)             217600    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 12800)             0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 20, 20, 64)       73792     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 20, 20, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 20, 20, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 40, 40, 32)       18464     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 40, 40, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 40, 40, 32)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 80, 80, 16)       4624      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 80, 80, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 80, 80, 16)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 160, 160, 3)      435       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 315,363\n",
            "Trainable params: 315,139\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's instantiate the VAE by combininb the encoder and the decoder layers."
      ],
      "metadata": {
        "id": "KIIDWhu9NOTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_out = decoder(encoder(encoder_input)[2])          # we feed in z from the encoder output\n",
        "VAE = keras.Model(encoder_input, decoder_out, name='VAE')\n",
        "\n",
        "VAE.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jek1XQ2oNUnb",
        "outputId": "22adc63c-0246-43d3-a6ca-9fd1cf060d47"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"VAE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 160, 160, 3)]     0         \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 16),              360576    \n",
            "                              (None, 16),                        \n",
            "                              (None, 16)]                        \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 160, 160, 3)       315363    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 675,939\n",
            "Trainable params: 675,235\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shall define the loss function now, it's made of the reconstruction loss that tries to ensure repoducibility of the data, and the KL divergence loss that tries to ensure that the learned (approximate) posterior is close to the true posterior. Since we have continuous values for the pixels, we cannot use the Bernoulli log loss (binary cross entropy) for the reconstruction loss, we shall use mean squared error. In a different version, we shall try to implement a continuous version of the Bernoulli log loss based on 1907.06845.\n",
        "\n",
        "We shall keep a relative weight beta between the two terms in the total loss as a hyperparameter. We may want to investigate the effects of varying this hyperparameter eventually."
      ],
      "metadata": {
        "id": "uD87axE7vwtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The custom loss function needs to be a callable of the form fn(true, pred) to be compatible with Model.compile() and Model.fit(). The reconstruction loss will calculate the mse between the true and predicted images directly. The kl divergence loss is a function of z_mean and z_log_var that will be used directly from the values while evaluating the forward pass. For further details, look up the source code for the compile() and fit() methods in the Model class, and also for train_step(), compute_loss(), and make_train_function()"
      ],
      "metadata": {
        "id": "5J7SuZUsK8mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beta = 1  # we shall vary this later\n",
        "\n",
        "def vae_loss(true,pred):\n",
        "  mse = losses.MeanSquaredError()\n",
        "  reconstruction_loss = (160*160*3)*mse(layers.flatten(true),layers.flatten(pred)).numpy()    # the input and the output for the model, which are 160*160*3 images will be taken as true and pred, respectively.\n",
        "\n",
        "  kl_div = tf.reduce_sum(-0.5*(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)), 1)     # summing along the columns, if we chose to take mean instead of sum at this step, we shouldn't multiply with the dimensions for the reconstruction loss.\n",
        "\n",
        "  return reconstruction_loss + beta*kl_div"
      ],
      "metadata": {
        "id": "CmLqVmtnMj1-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VAE.compile(optimizer='adam',loss=vae_loss)"
      ],
      "metadata": {
        "id": "CgbuzdhsUJ6w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to load our dataset, and train the VAE on it. We shall use the cats and dogs img dataset from this [repo](https://github.com/AtSourav/CatsnDogs_VAE.git)"
      ],
      "metadata": {
        "id": "EABBdq9_V0rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/AtSourav/CatsnDogs_img_dataset.git           # ! let's us use shell commands"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbddDD4WVYQi",
        "outputId": "44bf578b-6c43-4bad-9d6a-d6815b4bf4c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CatsnDogs_img_dataset'...\n",
            "remote: Enumerating objects: 5745, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 5745 (delta 1), reused 0 (delta 0), pack-reused 5739\u001b[K\n",
            "Receiving objects: 100% (5745/5745), 44.62 MiB | 31.45 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p3yYNpydIoU",
        "outputId": "b8680f16-2cef-49dc-95df-e6d6d71b4498"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CatsnDogs_img_dataset  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have cloned the repo with the dataset here so we can access it directly."
      ],
      "metadata": {
        "id": "_BgM7BY9eBbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls CatsnDogs_img_dataset/Dataset_aug | sed -n 20p     # -n sed asks not to print every line, 20p specifies that we want it to print the 20th entry"
      ],
      "metadata": {
        "id": "FnBwCUAhd4-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cfb24f7-7098-452a-8591-9a8e24817698"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cat_1018.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shall now make a train and validation dataset from the images in Dataset_aug folder, and also normalize images to have pixel values between 0 and 1 as opposed to 0 and 255."
      ],
      "metadata": {
        "id": "1tfCwXBYqNAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "img_dir = 'CatsnDogs_img_dataset/Dataset_aug/'\n",
        "\n",
        "\n",
        "data_train = utils.image_dataset_from_directory(img_dir, labels=None, validation_split=0.1, subset=\"training\", seed=111, image_size=(160,160), color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
        "\n",
        "data_valid = utils.image_dataset_from_directory(img_dir, labels=None, validation_split=0.1, subset=\"validation\", seed=111, image_size=(160,160), color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
        "\n",
        "for image_batch in data_train:\n",
        "  print(image_batch.shape)\n",
        "  break\n",
        "\n",
        "for image_batch in data_valid:\n",
        "  print(image_batch.shape)\n",
        "  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNWP8QDdc5I8",
        "outputId": "2af8dc3f-f26a-42af-c411-6559e0b21d80"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5110 files belonging to 1 classes.\n",
            "Using 4599 files for training.\n",
            "Found 5110 files belonging to 1 classes.\n",
            "Using 511 files for validation.\n",
            "(128, 160, 160, 3)\n",
            "(128, 160, 160, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_za54KDtxIFB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}